{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-19T09:18:23.402996321Z",
     "start_time": "2023-10-19T09:18:23.359719465Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import xlsxwriter\n",
    "from dotenv import load_dotenv\n",
    "import uuid\n",
    "load_dotenv()\n",
    "\n",
    "# UPLOAD_FOLDER = os.getenv('UPLOAD_FOLDER')\n",
    "# RESULTS_FOLDER = os.getenv('RESULTS_FOLDER')\n",
    "\n",
    "UPLOAD_FOLDER = './UPLOAD_FOLDER/'\n",
    "RESULTS_FOLDER = './RESULTS_FOLDER/'\n",
    "\n",
    "# os.walk traverse all files in path, and return a tuple\n",
    "\n",
    "if os.path.exists(UPLOAD_FOLDER) and os.path.isdir(UPLOAD_FOLDER):\n",
    "    path_upload, dirs_upload, files_upload = next(os.walk(UPLOAD_FOLDER))\n",
    "else:\n",
    "    print(f\"The path {UPLOAD_FOLDER} either doesn't exist or is not a directory\")\n",
    "upload_file_count = len(files_upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-19T09:18:25.060845007Z",
     "start_time": "2023-10-19T09:18:24.477266004Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File was successfully created at Merchant_MID_Report_10c2a24c-c5e1-4a32-a50b-5c1f76a95056.xlsx\n"
     ]
    }
   ],
   "source": [
    "def generate_report():\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for file in range(upload_file_count):\n",
    "        # Skip hidden files\n",
    "        if files_upload[file].startswith('.'):\n",
    "            continue\n",
    "        # Load the Excel file\n",
    "        try:\n",
    "            df = pd.read_excel(UPLOAD_FOLDER + files_upload[file])\n",
    "        except Exception as e:\n",
    "            try:\n",
    "                df = pd.read_csv(UPLOAD_FOLDER + files_upload[file], sep=',', header=0)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "        # Keep relevant columns and drop rows with missing 'Merchant' or 'Status'\n",
    "        df = df[['Merchant', 'MID', 'Transaction Date', 'Status', 'Amount', 'Payer Country', 'Brand', 'Issuer',\n",
    "                 'Decline reason']]\n",
    "        df = df.dropna(subset=['Merchant', 'Status'])\n",
    "\n",
    "        # Group data by Merchant and MID\n",
    "        grouped_data = df.groupby(['Merchant', 'MID'])\n",
    "\n",
    "        # Initialize a dictionary to hold data for each merchant\n",
    "        final_merchant_data = {}\n",
    "\n",
    "        # Iterate through each group to generate reports\n",
    "        for (merchant, mid), group_df in grouped_data:\n",
    "            merchant_mid_data = []\n",
    "\n",
    "            # Calculate approved, failed transactions and their ratio\n",
    "            status_count = group_df['Status'].value_counts()\n",
    "            approved_count = status_count.get('success', 0)\n",
    "            failed_count = status_count.get('fail', 0)\n",
    "            total_count = approved_count + failed_count\n",
    "            approval_ratio = approved_count / total_count if total_count > 0 else 0\n",
    "            summary_df = pd.DataFrame({\n",
    "                'Metric': ['Total Transactions', 'Approved Transactions', 'Failed Transactions', 'Approval Ratio',\n",
    "                           'Total Amount', 'Total Approved Amount'],\n",
    "                'Value': [total_count, approved_count, failed_count, approval_ratio, group_df['Amount'].sum(),\n",
    "                          group_df[group_df['Status'] == 'success']['Amount'].sum()]\n",
    "            })\n",
    "            merchant_mid_data.append(('MID Summary', summary_df))\n",
    "\n",
    "            # Summarize decline reasons (if available)\n",
    "            if 'Decline reason' in group_df.columns:\n",
    "                decline_reasons = group_df[group_df['Status'] == 'fail']['Decline reason'].value_counts().reset_index()\n",
    "                decline_reasons.columns = ['Decline Reason', 'Count']\n",
    "                merchant_mid_data.append(('Decline Summary', decline_reasons))\n",
    "\n",
    "            # Summarize payer countries\n",
    "            country_summary = group_df['Payer Country'].value_counts().reset_index()\n",
    "            country_summary.columns = ['Country', 'Count']\n",
    "            country_approval_ratio = group_df.groupby('Payer Country')['Status'].apply(\n",
    "                lambda x: (x == 'success').sum() / len(x)).reset_index()\n",
    "            country_approval_ratio.columns = ['Country', 'Approval Ratio']\n",
    "            country_summary = pd.merge(country_summary, country_approval_ratio, on='Country', how='left')\n",
    "            merchant_mid_data.append(('Country Summary', country_summary))\n",
    "\n",
    "            # Card brand summary\n",
    "            card_brand_summary = group_df.groupby('Brand')['Status'].apply(\n",
    "                lambda x: (x == 'success').sum() / len(x)).reset_index()\n",
    "            card_brand_summary.columns = ['Card Brand', 'Approval Ratio']\n",
    "            merchant_mid_data.append(('Card Brand Summary', card_brand_summary))\n",
    "\n",
    "            # Issuer summary\n",
    "            issuer_summary = group_df['Issuer'].value_counts().reset_index()\n",
    "            issuer_summary.columns = ['Issuer', 'Count']\n",
    "            merchant_mid_data.append(('Issuer Summary', issuer_summary))\n",
    "\n",
    "            # Adding the underlying data to the report content\n",
    "            merchant_mid_data.append(('Underlying Data', group_df))\n",
    "\n",
    "            final_merchant_data[(merchant, mid)] = merchant_mid_data\n",
    "\n",
    "        # Generate Excel report with underlying data\n",
    "        unique_id = str(uuid.uuid4())\n",
    "        output_file_path = f'Merchant_MID_Report_{unique_id}.xlsx'\n",
    "        try:\n",
    "            with pd.ExcelWriter(RESULTS_FOLDER + output_file_path, engine='xlsxwriter') as writer:\n",
    "                existing_sheets = set()  # To track existing sheet names\n",
    "                for (merchant, mid), content in final_merchant_data.items():\n",
    "                    sheet_name = f\"{merchant}_{mid}\".replace(\" \", \"_\")[:31]  # Limit to 31 characters for Excel sheet names\n",
    "    \n",
    "                    # Add a suffix if sheet name already exists\n",
    "                    suffix = 1\n",
    "                    original_sheet_name = sheet_name\n",
    "                    while sheet_name in existing_sheets:\n",
    "                        sheet_name = f\"{original_sheet_name}_{suffix}\".replace(\" \", \"_\")[:31]\n",
    "                        suffix += 1\n",
    "                    existing_sheets.add(sheet_name)\n",
    "    \n",
    "                    workbook = writer.book\n",
    "                    worksheet = workbook.add_worksheet(sheet_name)\n",
    "                    row = 0\n",
    "                    title_format = workbook.add_format({'bold': True, 'bg_color': '#ADD8E6', 'border': 1, 'align': 'center'})\n",
    "                    header_format = workbook.add_format({'bold': True, 'bg_color': '#F0E68C', 'border': 1, 'align': 'center'})\n",
    "                    cell_format = workbook.add_format({'border': 1})\n",
    "                    percent_format = workbook.add_format({'num_format': '0.00%', 'border': 1})\n",
    "                    for title, df in content:\n",
    "                        worksheet.merge_range(row, 0, row, len(df.columns) - 1, title, title_format)\n",
    "                        row += 1\n",
    "                        for c_idx, column_name in enumerate(df.columns, start=0):\n",
    "                            worksheet.write(row, c_idx, column_name, header_format)\n",
    "                        for r_idx, df_row in enumerate(df.values, start=row + 1):\n",
    "                            for c_idx, value in enumerate(df_row, start=0):\n",
    "                                # Check and replace NaN or INF values with an empty string\n",
    "                                if pd.isna(value) or value == float('inf') or value == float('-inf'):\n",
    "                                    value = \"\"\n",
    "                                if isinstance(value, float) and 0 <= value <= 1:\n",
    "                                    worksheet.write(r_idx, c_idx, value, percent_format)\n",
    "                                else:\n",
    "                                    worksheet.write(r_idx, c_idx, value, cell_format)\n",
    "                        row += len(df) + 2\n",
    "                print(f'File was successfully created at {output_file_path}')\n",
    "        except Exception as e:\n",
    "            print(f'An error occurred while creating the file: {e}')\n",
    "            print(f'Details: {e.__class__.__name__} - {str(e)}')\n",
    "            continue\n",
    "if __name__ == '__main__':\n",
    "    generate_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
