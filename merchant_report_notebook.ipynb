{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T08:37:13.499171636Z",
     "start_time": "2023-10-18T08:37:13.154115311Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import xlsxwriter\n",
    "from dotenv import load_dotenv\n",
    "import uuid\n",
    "load_dotenv()\n",
    "\n",
    "UPLOAD_FOLDER = os.getenv('UPLOAD_FOLDER')\n",
    "RESULTS_FOLDER = os.getenv('RESULTS_FOLDER')\n",
    "\n",
    "# os.walk traverse all files in path, and return a tuple\n",
    "path_upload, dirs_upload, files_upload = next(os.walk(UPLOAD_FOLDER))\n",
    "upload_file_count = len(files_upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T08:37:17.819036500Z",
     "start_time": "2023-10-18T08:37:15.888190422Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Merchant', 'MID', 'Transaction Date', 'Status', 'Amount',\\n       'Payer Country', 'Brand', 'Issuer', 'Decline reason'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 114\u001B[0m\n\u001B[1;32m    111\u001B[0m                     row \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(df) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m--> 114\u001B[0m     \u001B[43mgenerate_report\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[2], line 15\u001B[0m, in \u001B[0;36mgenerate_report\u001B[0;34m()\u001B[0m\n\u001B[1;32m     12\u001B[0m         \u001B[38;5;28mprint\u001B[39m(e)\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# Keep relevant columns and drop rows with missing 'Merchant' or 'Status'\u001B[39;00m\n\u001B[0;32m---> 15\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mMerchant\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mMID\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mTransaction Date\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mStatus\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mAmount\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mPayer Country\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mBrand\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mIssuer\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m         \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mDecline reason\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m     17\u001B[0m df \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mdropna(subset\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMerchant\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mStatus\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# Group data by Merchant and MID\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/merchant_report/venv/lib/python3.9/site-packages/pandas/core/frame.py:3902\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3900\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_iterator(key):\n\u001B[1;32m   3901\u001B[0m         key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(key)\n\u001B[0;32m-> 3902\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_indexer_strict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcolumns\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m   3904\u001B[0m \u001B[38;5;66;03m# take() does not accept boolean indexers\u001B[39;00m\n\u001B[1;32m   3905\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(indexer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mbool\u001B[39m:\n",
      "File \u001B[0;32m~/PycharmProjects/merchant_report/venv/lib/python3.9/site-packages/pandas/core/indexes/base.py:6114\u001B[0m, in \u001B[0;36mIndex._get_indexer_strict\u001B[0;34m(self, key, axis_name)\u001B[0m\n\u001B[1;32m   6111\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   6112\u001B[0m     keyarr, indexer, new_indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reindex_non_unique(keyarr)\n\u001B[0;32m-> 6114\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raise_if_missing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkeyarr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   6116\u001B[0m keyarr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtake(indexer)\n\u001B[1;32m   6117\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, Index):\n\u001B[1;32m   6118\u001B[0m     \u001B[38;5;66;03m# GH 42790 - Preserve name from an Index\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/merchant_report/venv/lib/python3.9/site-packages/pandas/core/indexes/base.py:6175\u001B[0m, in \u001B[0;36mIndex._raise_if_missing\u001B[0;34m(self, key, indexer, axis_name)\u001B[0m\n\u001B[1;32m   6173\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m use_interval_msg:\n\u001B[1;32m   6174\u001B[0m         key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(key)\n\u001B[0;32m-> 6175\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNone of [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m] are in the [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00maxis_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   6177\u001B[0m not_found \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(ensure_index(key)[missing_mask\u001B[38;5;241m.\u001B[39mnonzero()[\u001B[38;5;241m0\u001B[39m]]\u001B[38;5;241m.\u001B[39munique())\n\u001B[1;32m   6178\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnot_found\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not in index\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mKeyError\u001B[0m: \"None of [Index(['Merchant', 'MID', 'Transaction Date', 'Status', 'Amount',\\n       'Payer Country', 'Brand', 'Issuer', 'Decline reason'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "def generate_report():\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for file in range(upload_file_count):\n",
    "        # Load the Excel file\n",
    "        try:\n",
    "            df = pd.read_excel(UPLOAD_FOLDER + files_upload[file])\n",
    "        except Exception as e:\n",
    "            try:\n",
    "                df = pd.read_csv(UPLOAD_FOLDER + files_upload[file], sep=',', header=0)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "        # Keep relevant columns and drop rows with missing 'Merchant' or 'Status'\n",
    "        df = df[['Merchant', 'MID', 'Transaction Date', 'Status', 'Amount', 'Payer Country', 'Brand', 'Issuer',\n",
    "                 'Decline reason']]\n",
    "        df = df.dropna(subset=['Merchant', 'Status'])\n",
    "\n",
    "        # Group data by Merchant and MID\n",
    "        grouped_data = df.groupby(['Merchant', 'MID'])\n",
    "\n",
    "        # Initialize a dictionary to hold data for each merchant\n",
    "        final_merchant_data = {}\n",
    "\n",
    "        # Iterate through each group to generate reports\n",
    "        for (merchant, mid), group_df in grouped_data:\n",
    "            merchant_mid_data = []\n",
    "\n",
    "            # Calculate approved, failed transactions and their ratio\n",
    "            status_count = group_df['Status'].value_counts()\n",
    "            approved_count = status_count.get('success', 0)\n",
    "            failed_count = status_count.get('fail', 0)\n",
    "            total_count = approved_count + failed_count\n",
    "            approval_ratio = approved_count / total_count if total_count > 0 else 0\n",
    "            summary_df = pd.DataFrame({\n",
    "                'Metric': ['Total Transactions', 'Approved Transactions', 'Failed Transactions', 'Approval Ratio',\n",
    "                           'Total Amount', 'Total Approved Amount'],\n",
    "                'Value': [total_count, approved_count, failed_count, approval_ratio, group_df['Amount'].sum(),\n",
    "                          group_df[group_df['Status'] == 'success']['Amount'].sum()]\n",
    "            })\n",
    "            merchant_mid_data.append(('MID Summary', summary_df))\n",
    "\n",
    "            # Summarize decline reasons (if available)\n",
    "            if 'Decline reason' in group_df.columns:\n",
    "                decline_reasons = group_df[group_df['Status'] == 'fail']['Decline reason'].value_counts().reset_index()\n",
    "                decline_reasons.columns = ['Decline Reason', 'Count']\n",
    "                merchant_mid_data.append(('Decline Summary', decline_reasons))\n",
    "\n",
    "            # Summarize payer countries\n",
    "            country_summary = group_df['Payer Country'].value_counts().reset_index()\n",
    "            country_summary.columns = ['Country', 'Count']\n",
    "            country_approval_ratio = group_df.groupby('Payer Country')['Status'].apply(\n",
    "                lambda x: (x == 'success').sum() / len(x)).reset_index()\n",
    "            country_approval_ratio.columns = ['Country', 'Approval Ratio']\n",
    "            country_summary = pd.merge(country_summary, country_approval_ratio, on='Country', how='left')\n",
    "            merchant_mid_data.append(('Country Summary', country_summary))\n",
    "\n",
    "            # Card brand summary\n",
    "            card_brand_summary = group_df.groupby('Brand')['Status'].apply(\n",
    "                lambda x: (x == 'success').sum() / len(x)).reset_index()\n",
    "            card_brand_summary.columns = ['Card Brand', 'Approval Ratio']\n",
    "            merchant_mid_data.append(('Card Brand Summary', card_brand_summary))\n",
    "\n",
    "            # Issuer summary\n",
    "            issuer_summary = group_df['Issuer'].value_counts().reset_index()\n",
    "            issuer_summary.columns = ['Issuer', 'Count']\n",
    "            merchant_mid_data.append(('Issuer Summary', issuer_summary))\n",
    "\n",
    "            # Adding the underlying data to the report content\n",
    "            merchant_mid_data.append(('Underlying Data', group_df))\n",
    "\n",
    "            final_merchant_data[(merchant, mid)] = merchant_mid_data\n",
    "\n",
    "        # Generate Excel report with underlying data\n",
    "        unique_id = str(uuid.uuid4())\n",
    "        output_file_path = f'Merchant_MID_Report_{unique_id}.xlsx'\n",
    "        with pd.ExcelWriter(RESULTS_FOLDER + output_file_path, engine='xlsxwriter') as writer:\n",
    "            existing_sheets = set()  # To track existing sheet names\n",
    "            for (merchant, mid), content in final_merchant_data.items():\n",
    "                sheet_name = f\"{merchant}_{mid}\".replace(\" \", \"_\")[:31]  # Limit to 31 characters for Excel sheet names\n",
    "\n",
    "                # Add a suffix if sheet name already exists\n",
    "                suffix = 1\n",
    "                original_sheet_name = sheet_name\n",
    "                while sheet_name in existing_sheets:\n",
    "                    sheet_name = f\"{original_sheet_name}_{suffix}\".replace(\" \", \"_\")[:31]\n",
    "                    suffix += 1\n",
    "                existing_sheets.add(sheet_name)\n",
    "\n",
    "                workbook = writer.book\n",
    "                worksheet = workbook.add_worksheet(sheet_name)\n",
    "                row = 0\n",
    "                title_format = workbook.add_format({'bold': True, 'bg_color': '#ADD8E6', 'border': 1, 'align': 'center'})\n",
    "                header_format = workbook.add_format({'bold': True, 'bg_color': '#F0E68C', 'border': 1, 'align': 'center'})\n",
    "                cell_format = workbook.add_format({'border': 1})\n",
    "                percent_format = workbook.add_format({'num_format': '0.00%', 'border': 1})\n",
    "                for title, df in content:\n",
    "                    worksheet.merge_range(row, 0, row, len(df.columns) - 1, title, title_format)\n",
    "                    row += 1\n",
    "                    for c_idx, column_name in enumerate(df.columns, start=0):\n",
    "                        worksheet.write(row, c_idx, column_name, header_format)\n",
    "                    for r_idx, df_row in enumerate(df.values, start=row + 1):\n",
    "                        for c_idx, value in enumerate(df_row, start=0):\n",
    "                            # Check and replace NaN or INF values with an empty string\n",
    "                            if pd.isna(value) or value == float('inf') or value == float('-inf'):\n",
    "                                value = \"\"\n",
    "                            if isinstance(value, float) and 0 <= value <= 1:\n",
    "                                worksheet.write(r_idx, c_idx, value, percent_format)\n",
    "                            else:\n",
    "                                worksheet.write(r_idx, c_idx, value, cell_format)\n",
    "                    row += len(df) + 2\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    generate_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
